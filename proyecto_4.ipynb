{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport re \nimport numpy\nfrom pyspark.ml.feature import Tokenizer\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.sql.functions import * \nfrom pyspark.sql.functions import length\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql import functions as f\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.sql.functions import col, when\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.ml.feature import StringIndexer\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["spark=SparkSession.builder.appName('mmarulandc').getOrCreate()\ncsv = '/FileStore/tables/articles1.csv'\ndf1 = spark.read.csv(csv).toPandas()\ndf1.head(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>_c1</th>\n      <th>_c2</th>\n      <th>_c3</th>\n      <th>_c4</th>\n      <th>_c5</th>\n      <th>_c6</th>\n      <th>_c7</th>\n      <th>_c8</th>\n      <th>_c9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>id</td>\n      <td>title</td>\n      <td>publication</td>\n      <td>author</td>\n      <td>date</td>\n      <td>year</td>\n      <td>month</td>\n      <td>url</td>\n      <td>content</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>17283</td>\n      <td>House Republicans Fret About Winning Their Hea...</td>\n      <td>New York Times</td>\n      <td>Carl Hulse</td>\n      <td>2016-12-31</td>\n      <td>2016.0</td>\n      <td>12.0</td>\n      <td>None</td>\n      <td>WASHINGTON  —   Congressional Republicans have...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#Creando un dataframe que contenga los contedidos de las publicaciones hechas y limpiando el contenido de caracteres especiales.\ndf1['_cleaned'] = [re.sub(r\"[^a-zA-Z0-9]+\",' ', str(x)) for x in df1['_c9']]\ndf1.head()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>_c1</th>\n      <th>_c2</th>\n      <th>_c3</th>\n      <th>_c4</th>\n      <th>_c5</th>\n      <th>_c6</th>\n      <th>_c7</th>\n      <th>_c8</th>\n      <th>_c9</th>\n      <th>_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>id</td>\n      <td>title</td>\n      <td>publication</td>\n      <td>author</td>\n      <td>date</td>\n      <td>year</td>\n      <td>month</td>\n      <td>url</td>\n      <td>content</td>\n      <td>content</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>17283</td>\n      <td>House Republicans Fret About Winning Their Hea...</td>\n      <td>New York Times</td>\n      <td>Carl Hulse</td>\n      <td>2016-12-31</td>\n      <td>2016.0</td>\n      <td>12.0</td>\n      <td>None</td>\n      <td>WASHINGTON  —   Congressional Republicans have...</td>\n      <td>WASHINGTON Congressional Republicans have a ne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>17284</td>\n      <td>Rift Between Officers and Residents as Killing...</td>\n      <td>New York Times</td>\n      <td>Benjamin Mueller and Al Baker</td>\n      <td>2017-06-19</td>\n      <td>2017.0</td>\n      <td>6.0</td>\n      <td>None</td>\n      <td>After the bullet shells get counted, the blood...</td>\n      <td>After the bullet shells get counted the blood ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>17285</td>\n      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n      <td>New York Times</td>\n      <td>Margalit Fox</td>\n      <td>2017-01-06</td>\n      <td>2017.0</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n      <td>When Walt Disney s Bambi opened in 1942 critic...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>17286</td>\n      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n      <td>New York Times</td>\n      <td>William McDonald</td>\n      <td>2017-04-10</td>\n      <td>2017.0</td>\n      <td>4.0</td>\n      <td>None</td>\n      <td>Death may be the great equalizer, but it isn’t...</td>\n      <td>Death may be the great equalizer but it isn t ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["#Para verificar que el procesamiento ocurrio correctamente, haremos un word cloud usando la libreria wordcloud para obtener una representacion visual de las palabras más comunes, esta es la clave para enteder la data y que vamos en el buen camino para el entrenamiento de modelos\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncount_vectorizer = CountVectorizer(stop_words='english')\n# Fit and transform the processed titles\ncount_data = count_vectorizer.fit_transform(df1['_cleaned'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["import warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\n# Load the LDA model from sk-learn\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\n \n# Helper function\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n        \n# Tweak the two parameters below\nnumber_topics = 5\nnumber_words = 10\n# Create and fit the LDA model\nlda = LDA()\nlda.fit(count_data)\n# Print the topics found by the LDA model\nprint(\"Topics found via LDA:\")\nprint_topics(lda, count_vectorizer, number_words)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Topics found via LDA:\n\nTopic #0:\ntrump clinton said donald campaign republican president people hillary 2016\n\nTopic #1:\nsaid isis military state attack syria islamic united war security\n\nTopic #2:\nsaid country european china world government europe people minister party\n\nTopic #3:\ncompany million new year business 000 said companies billion percent\n\nTopic #4:\ntrump said mr president clinton news house obama white russia\n\nTopic #5:\nlike people just don know think said time going ve\n\nTopic #6:\nsaid court law federal states state health president government house\n\nTopic #7:\nsaid mr family school new ms women children students years\n\nTopic #8:\nsaid people like water new says study dr health just\n\nTopic #9:\nsaid police told according officers cnn people man reported city\n</div>"]}}],"execution_count":6}],"metadata":{"name":"mmarulandc","notebookId":2520598618048206},"nbformat":4,"nbformat_minor":0}
